# Welcome to My Summer!

Hi! I'm your first file in **Summer training**. If you want to learn about my first summer at AHU, you can read me.  

remember tell yourself “好像美好的事物都包裹这一种永别感，好像这一刻再也不会有了。”  
“坐在教西207的第一排。窗外，树荫抓住了夏季倾泻的阳光，星星点点从指缝间漏出，散落在桌角。这样的夏天，也许再也不会有了吧。”

# 参与项目

AutoDAN
LLMselfdefense
大模型输出的安全性检测
排版了一篇论文，写了基金的一部分
了解了几个算法
（这些部分将在内部文件中再次出现，对照食用效果更佳）

## AutoDAN

我的第一个项目，第三篇论文，第二次尝试复现，第一次在代码层次改动一个项目
为结构化离散数据优化设计的**分层遗传算法**
*算法设计*
 <tab>1.基于token梯度的离散优化与贪心查找（同义词替换）
 <tab>2.大模型的抽象化——看作是对于句子概率预测的映射，更进一步看成上一token对于下一token的映射，彻底转化为概率计算式，将输出可视化（因为基于token，所以需要知道**分词法**以及**训练参数**）
 <tab>3.适应度函数取最大似然
  <tab>4.句子以及段落两级进行同义词替换（同义词来自初始种群与wordnet）
  <tab>最难的是开源模型的部署，遇见了反复调试其在线查找部分以改到本地；改到本地后反复爆显存因为本地部署所需算力太大，实验室两张4090都不够用；然后又涉及模型的量化，缺了微调
## LLMselfdefense

大模型的自我输出检查机制，其实就是把输出的文本再输回去，当分类器用一遍，“is it harmful?"
<tab>1.难的是刚开始的api调用，把接口调用的代码搞错了，一直配不平，然后就问了徐光泰，发现代码写错了，最后的区别是在于他做了输出的简化
<tab>2.找越狱Q&A数据集

## 大模型输出的安全性检测

是学长写的论文，以及一系列论证。具体的实现思路是想在大模型流式输出的时候就进行安全性的判别，调用第三方大模型进行安全性检测
<tab>1.涉及到的问题有第三方模型api查询与调用，大模型的输出输入，分类器prompt的设计
<tab>2.最后我整理收集的确实技术有**滑动窗口**这一**数据处理/流量控制**工具
大模型的结构化输出以与内容提取（json格式）——支持大模型流式输出的json提取工具
相关优化算法的设计（开源模型）

## 基金

基于流式生成模型的文本安全性检测，我设计了基于损失函数的算法
<tab>1.将大模型看作是概率的映射，求出极大似然损失函数，以此为基础制作分类器
<tab>2.算法基础：当函数值大于0.693，则失败
<tab>3.基于此，设计"is it harmful",当输出概率小于0.693时，认定不安全
<tab>4.为防止不准确或天然对抗样本，取排名靠前的token进行替换并取平均值作为改输出的安全值

## 一些虎头蛇尾

1.文本/媒体识别（ai输出识别）
2.提示词注入攻击

# 算法

梯度下降/遗传算法
